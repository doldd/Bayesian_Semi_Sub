{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda. Device:  NVIDIA GeForce RTX 3080 Ti\n",
      "Device:  cuda:0\n",
      "env: WANDB_BASE_URL=http://141.37.176.203:8080\n",
      "env: WANDB_NOTEBOOK_NAME=./melanoma_laplace.ipynb\n",
      "Figure size= [3.2378580323785804, 2.00110631475682]\n"
     ]
    }
   ],
   "source": [
    "from laplace import Laplace\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "from src.semiSub_model import getModel\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "if torch.cuda.is_available() and 1:\n",
    "    print(\"Use cuda. Device: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device('cuda', torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"Device: \", device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env WANDB_BASE_URL http://141.37.176.203:8080\n",
    "%env WANDB_NOTEBOOK_NAME ./melanoma_laplace.ipynb\n",
    "\n",
    "def get_figsize(columnwidth, wf=0.5, hf=(5.**0.5-1.0)/2.0, ):\n",
    "    \"\"\"Parameters:\n",
    "    - wf [float]:  width fraction in columnwidth units\n",
    "    - hf [float]:  height fraction in columnwidth units.\n",
    "                    Set by default to golden ratio.\n",
    "    - columnwidth [float]: width of the column in latex. Get this from LaTeX \n",
    "                            using \\showthe\\columnwidth\n",
    "    Returns:  [fig_width,fig_height]: that should be given to matplotlib\n",
    "    \"\"\"\n",
    "    fig_width_pt = columnwidth*wf \n",
    "    inches_per_pt = 1.0/72.27               # Convert pt to inch\n",
    "    fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "    fig_height = fig_width*hf      # height in inches\n",
    "    return [fig_width, fig_height]\n",
    "\n",
    "\n",
    "figsize = get_figsize(234*2)\n",
    "print(\"Figure size=\", figsize)\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    # \"text.latex.preamble\": r'\\usepackage{amsfonts}',\n",
    "    \"font.family\": \"Nimbus Sans\",\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"font.size\": 10,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 9,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9\n",
    "}\n",
    "plt.rcParams.update(tex_fonts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemiAdditive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCnnSemi(\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (valid_metrics): MetricCollection(\n",
       "    (BinaryCalibrationError): BinaryCalibrationError()\n",
       "    (BinaryAUROC): BinaryAUROC()\n",
       "    (BinaryAccuracy): BinaryAccuracy()\n",
       "    (BinaryAveragePrecision): BinaryAveragePrecision()\n",
       "    (BinaryF1Score): BinaryF1Score(),\n",
       "    prefix=valid/\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (BinaryCalibrationError): BinaryCalibrationError()\n",
       "    (BinaryAUROC): BinaryAUROC()\n",
       "    (BinaryAccuracy): BinaryAccuracy()\n",
       "    (BinaryAveragePrecision): BinaryAveragePrecision()\n",
       "    (BinaryF1Score): BinaryF1Score(),\n",
       "    prefix=test/\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): Tanh()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (13): Tanh()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lin): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       "  (dnn): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): Tanh()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): Tanh()\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (7): Tanh()\n",
       "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (10): Tanh()\n",
       "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (13): Tanh()\n",
       "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): Tanh()\n",
       "      (5): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (structure_lin): Linear(in_features=1, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.base_models import BaseModel\n",
    "from src.semiSub_model import SemiAdditive\n",
    "\n",
    "class SimpleCnnt(BaseModel):\n",
    "    def __init__(self, output_dim, weight_decay: float = 0., lr: float = 1e-4, seed: int = None, **kwargs):\n",
    "        super(SimpleCnnt, self).__init__(**kwargs)\n",
    "        if seed is not None:\n",
    "            pl.seed_everything(seed)\n",
    "        # self.save_hyperparameters('num_bends', 'lr', 'seed')\n",
    "        self.save_hyperparameters('weight_decay', 'lr', 'seed')\n",
    "        self.conv = nn.Sequential(nn.Conv2d(3, 32, 3, ),  # 128\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2, ),  # 126\n",
    "                                  nn.Conv2d(32, 32, 3),  # 63\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2, ),  # 61\n",
    "                                  nn.Conv2d(32, 64, 3),  # 30\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2, ),  # 28\n",
    "                                  nn.Conv2d(64, 64, 3),  # 14\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2, ),  # 12\n",
    "                                  nn.Conv2d(64, 128, 3),  # 6\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2, )  # 4\n",
    "                                  )\n",
    "        self.lin = nn.Sequential(nn.Flatten(),  # 2\n",
    "                                 nn.Linear(2 * 2 * 128, 128),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(128, 128),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(128, output_dim)\n",
    "                                 )\n",
    "        self.dnn = nn.Sequential(self.conv, self.lin)\n",
    "\n",
    "    def forward(self, u):\n",
    "        return self.dnn(u)\n",
    "    \n",
    "\n",
    "class SimpleCnnSemi(SemiAdditive, SimpleCnnt):\n",
    "    def __init__(self, num_structure, output_dim, **kwargs):\n",
    "        super(SimpleCnnSemi, self).__init__(num_structure=num_structure, output_dim=output_dim, **kwargs)\n",
    "        self.u_shape = (3,128,128)\n",
    "        self.x_input_feature = num_structure\n",
    "\n",
    "    @staticmethod\n",
    "    def pseudo_inv_softmax(x):\n",
    "        y1 = -torch.log(x[...,1:])\n",
    "        y2 = -torch.log(x[...,0:1])\n",
    "        return torch.hstack([y1,y2])\n",
    "    \n",
    "    def forward(self, data) -> torch.Tensor:\n",
    "        x = data[:,-self.x_input_feature:]\n",
    "        u = data[:,:-self.x_input_feature].reshape(-1,*self.u_shape)\n",
    "        logit_1 = super().forward(u, x)\n",
    "        p1 = torch.sigmoid(logit_1) # p(y=1|x,u)\n",
    "        pseudo_logits = self.pseudo_inv_softmax(torch.hstack([1-p1, p1]))\n",
    "        return pseudo_logits\n",
    "        \n",
    "    def training_step(self, train_batch, batch_idx) -> torch.Tensor:\n",
    "        data, y = train_batch\n",
    "        if y.device != self.device:\n",
    "            y = y.to(device=self.device)\n",
    "            data = data.to(device=self.device)\n",
    "        eta_prime = self(data)\n",
    "        loss = self.loss_fn(eta_prime, y)\n",
    "        self.log('train/loss', loss, on_step=True, on_epoch=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> dict:\n",
    "        data, y = batch\n",
    "        eta_prime = self(data)\n",
    "        loss = self.loss_fn(eta_prime, y)\n",
    "        self.log('valid/loss', loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.valid_metrics(eta_prime, y)\n",
    "        self.log_dict(self.valid_metrics, on_step=False, on_epoch=True)\n",
    "        return eta_prime.detach()\n",
    "\n",
    "    def test_step(self, batch, batch_idx) -> dict:\n",
    "        data, y = batch\n",
    "        eta_prime = self(data)\n",
    "        loss = self.loss_fn(eta_prime, y)\n",
    "        self.log('test/loss', loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.test_metrics(eta_prime, y)\n",
    "        self.log_dict(self.test_metrics, on_step=False, on_epoch=True)\n",
    "        return eta_prime.detach()\n",
    "SimpleCnnSemi(1,2, loss_fn=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train initial model\n",
    "- Using corssentropy loss because Laplace framework requires this classification loss\n",
    "- Same CNN as in our subspace exp used\n",
    "- changed one-dimensional output $\\eta$ into $\\eta' = \\text{inv}_{\\text{softmax}}\\left(\\begin{bmatrix} \\sigma(\\eta) \\\\ 1 - \\sigma(\\eta) \\end{bmatrix}\\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mddold\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231012_120103-24m7jzgy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='http://141.37.176.203:8080/ddold/laplace_melanoma/runs/24m7jzgy' target=\"_blank\">laplace</a></strong> to <a href='http://141.37.176.203:8080/ddold/laplace_melanoma' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='http://141.37.176.203:8080/ddold/laplace_melanoma' target=\"_blank\">http://141.37.176.203:8080/ddold/laplace_melanoma</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='http://141.37.176.203:8080/ddold/laplace_melanoma/runs/24m7jzgy' target=\"_blank\">http://141.37.176.203:8080/ddold/laplace_melanoma/runs/24m7jzgy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact melanom_dataset:latest, 89.10MB. 35134 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   35134 of 35134 files downloaded.  \n",
      "Done. 0:0:12.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move data to from dataset/siim_isic/melanom_ds to RAM /dev/shm/melanom_ds...\n",
      "data_dir:  dataset/siim_isic\n",
      "DM setup done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/home/daniel/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'metric_collection' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['metric_collection'])`.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 10\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemiAdditive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_fn       | CrossEntropyLoss | 0     \n",
      "1 | valid_metrics | MetricCollection | 0     \n",
      "2 | test_metrics  | MetricCollection | 0     \n",
      "3 | conv          | Sequential       | 139 K \n",
      "4 | lin           | Sequential       | 82.3 K\n",
      "5 | dnn           | Sequential       | 221 K \n",
      "6 | structure_lin | Linear           | 1     \n",
      "---------------------------------------------------\n",
      "221 K     Trainable params\n",
      "0         Non-trainable params\n",
      "221 K     Total params\n",
      "0.887     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [ModelCheckpoint(dirpath\u001b[39m=\u001b[39mckp_dir, save_top_k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid/loss\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m                      logger\u001b[39m=\u001b[39mwandb_logger,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m                      callbacks\u001b[39m=\u001b[39mcallbacks)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_dataloaders\u001b[39m=\u001b[39;49mtrain_loader, val_dataloaders\u001b[39m=\u001b[39;49mvalid_cuda_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m best_model \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(model)\u001b[39m.\u001b[39mload_from_checkpoint(checkpoint_path\u001b[39m=\u001b[39mcallbacks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mbest_model_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m trainer\u001b[39m.\u001b[39mtest(best_model, dataloaders\u001b[39m=\u001b[39mtest_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1021\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1020\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1021\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1023\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1050\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1049\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1052\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:376\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    375\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 376\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    380\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:393\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    392\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 393\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m     data, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     eta_prime \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(eta_prime, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mvalid/loss\u001b[39m\u001b[39m'\u001b[39m, loss, on_step\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, on_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sync_dist\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m x \u001b[39m=\u001b[39m data[:,\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_input_feature:]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m u \u001b[39m=\u001b[39m data[:,:\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_input_feature]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_shape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m logit_1 \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(u, x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m p1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(logit_1) \u001b[39m# p(y=1|x,u)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m pseudo_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpseudo_inv_softmax(torch\u001b[39m.\u001b[39mhstack([\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mp1, p1]))\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from src.plot import exclude_project_code_dirs\n",
    "from utils_datamodel.pl_utils import MelanomDataModuleFromSplit\n",
    "from torchmetrics import MetricCollection, CalibrationError, AUROC, Accuracy, AveragePrecision, F1Score\n",
    "import os\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from utils_datamodel.utils import FastFillTensorDataLoader\n",
    "\n",
    "wandb_logger = WandbLogger(project='laplace_melanoma', log_model=False, name='laplace',\n",
    "                            group=\"SimpleCnn\", resume='never')\n",
    "# define a metric we are interested in the best of\n",
    "wandb_logger.experiment.define_metric(\"valid/loss\", summary=\"min\")\n",
    "wandb_logger.experiment.define_metric(\"valid/CalibrationError\", summary=\"min\")\n",
    "wandb_logger.experiment.define_metric(\"valid/AUROC\", summary=\"max\")\n",
    "wandb_logger.experiment.define_metric(\"valid/Accuracy\", summary=\"max\")\n",
    "wandb_logger.experiment.define_metric(\"valid/AveragePrecision\", summary=\"max\")\n",
    "wandb_logger.experiment.define_metric(\"valid/F1Score\", summary=\"max\")\n",
    "# wandb_logger.experiment.define_metric(\"test/loss\", summary=\"min\")\n",
    "# wandb_logger.experiment.define_metric(\"test/AUROC\", summary=\"max\")\n",
    "\n",
    "\n",
    "\n",
    "def target_trans(y):\n",
    "    return torch.tensor(y).to(dtype=torch.long)\n",
    "transform = nn.Sequential(torchvision.transforms.ConvertImageDtype(torch.float32),\n",
    "                            torchvision.transforms.Normalize((0.8061, 0.6210, 0.5914), (0.1484, 0.1748, 0.1999)))\n",
    "transform = torch.jit.trace(transform, torch.randint(0, 255, (3, 128, 128), dtype=torch.uint8))\n",
    "dm = MelanomDataModuleFromSplit(wandb_logger=wandb_logger,\n",
    "                                split=1,\n",
    "                                batch_size=256,\n",
    "                                reuse_artifact=True,\n",
    "                                meta_features=['age_approx'],\n",
    "                                transform_test=transform,\n",
    "                                transform_train=transform,\n",
    "                                target_transform=target_trans)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "# preload data\n",
    "u, x, y = [], [], []\n",
    "for (uu, xx), yy in dm.train_dataloader():\n",
    "    u.append(uu)\n",
    "    x.append(xx)\n",
    "    y.append(yy)\n",
    "u = torch.vstack(u) # .to(device=device)\n",
    "x = torch.vstack(x) # .to(device=device)\n",
    "y = torch.hstack(y) # .to(device=device)\n",
    "data = torch.cat([u.reshape(u.shape[0],-1), x], dim=1)\n",
    "dataset = torch.utils.data.TensorDataset(data,y)\n",
    "train_loader = FastFillTensorDataLoader(dataset, batch_size=256, shuffle=True, pin_memory=False)\n",
    "\n",
    "u, x, y = [], [], []\n",
    "for (uu, xx), yy in dm.val_dataloader():\n",
    "    u.append(uu)\n",
    "    x.append(xx)\n",
    "    y.append(yy)\n",
    "u = torch.vstack(u).to(device=device)\n",
    "x = torch.vstack(x).to(device=device)\n",
    "y = torch.hstack(y).to(device=device)\n",
    "data = torch.cat([u.reshape(u.shape[0],-1), x], dim=1)\n",
    "dataset = torch.utils.data.TensorDataset(data,y)\n",
    "valid_cuda_loader = FastFillTensorDataLoader(dataset, batch_size=len(dataset)//10, shuffle=False, pin_memory=False)\n",
    "\n",
    "u, x, y = [], [], []\n",
    "for (uu, xx), yy in dm.test_dataloader():\n",
    "    u.append(uu)\n",
    "    x.append(xx)\n",
    "    y.append(yy)\n",
    "u = torch.vstack(u) # .to(device=device)\n",
    "x = torch.vstack(x) # .to(device=device)\n",
    "y = torch.hstack(y) # .to(device=device)\n",
    "data = torch.cat([u.reshape(u.shape[0],-1), x], dim=1)\n",
    "dataset = torch.utils.data.TensorDataset(data,y)\n",
    "test_loader = FastFillTensorDataLoader(dataset, batch_size=len(dataset)//10, shuffle=False, pin_memory=False)\n",
    "\n",
    "model = SimpleCnnSemi(seed=10, weight_decay=1e-4, lr=5e-3, num_structure=1, output_dim=1,\n",
    "                  loss_fn=torch.nn.CrossEntropyLoss(reduction='mean'),\n",
    "                  metric_collection=MetricCollection([CalibrationError(task=\"multiclass\", num_classes=2),\n",
    "                                                     AUROC(task=\"multiclass\", num_classes=2),\n",
    "                                                     Accuracy(task=\"multiclass\", num_classes=2),\n",
    "                                                     AveragePrecision(task=\"multiclass\", num_classes=2),\n",
    "                                                     F1Score(task=\"multiclass\", num_classes=2, threshold=0.1)\n",
    "                                                     ]))\n",
    "ckp_dir = os.path.join(wandb_logger.experiment.dir, \"checkpoints\")\n",
    "callbacks = [ModelCheckpoint(dirpath=ckp_dir, save_top_k=1, monitor=\"valid/loss\")]\n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "                     logger=wandb_logger,\n",
    "                     callbacks=callbacks)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_cuda_loader)\n",
    "best_model = type(model).load_from_checkpoint(checkpoint_path=callbacks[0].best_model_path)\n",
    "trainer.test(best_model, dataloaders=test_loader)\n",
    "\n",
    "wandb_logger.experiment.log_code(\"./\", name=f\"project_code_{wandb_logger.experiment.id}\", exclude_fn=exclude_project_code_dirs) # exclude drbayes, wandb, dnn-mode-connectivity\n",
    "# save model as artifact\n",
    "art = wandb.Artifact(f\"model_state_{wandb_logger.experiment.id}\", type=model.__class__.__name__, description=\"Simple CNN Model\")\n",
    "art.add_dir(ckp_dir)\n",
    "wandb_logger.experiment.log_artifact(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  Parameter containing:\n",
      "tensor([[0.5665]], requires_grad=True)\n",
      "Bias:  Parameter containing:\n",
      "tensor([-3.5606], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Theta: \", model.structure_lin.weight)\n",
    "print(\"Bias: \", model.dnn[1][-1].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  Parameter containing:\n",
      "tensor([[0.5475]], requires_grad=True)\n",
      "Bias:  Parameter containing:\n",
      "tensor([-3.6316], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Theta: \", best_model.structure_lin.weight)\n",
    "print(\"Bias: \", best_model.dnn[1][-1].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Laplace approximation on last layer and theta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlaplace\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m ModuleNameSubnetMask\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m subnetwork_mask \u001b[39m=\u001b[39m ModuleNameSubnetMask(best_model, module_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mstructure_lin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlin.5\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m subnetwork_mask\u001b[39m.\u001b[39mselect()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B141.37.176.86/home/daniel/remote/semi_subspace/melanoma_laplace.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m subnetwork_indices \u001b[39m=\u001b[39m subnetwork_mask\u001b[39m.\u001b[39mindices\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "from laplace.utils import ModuleNameSubnetMask\n",
    "subnetwork_mask = ModuleNameSubnetMask(best_model, module_names=['structure_lin', 'lin.5'])\n",
    "subnetwork_mask.select()\n",
    "subnetwork_indices = subnetwork_mask.indices\n",
    "\n",
    "\n",
    "# Define and fit subnetwork LA using the specified subnetwork indices\n",
    "la = Laplace(best_model.to(device=device), 'classification',\n",
    "             subset_of_weights='subnetwork',\n",
    "             hessian_structure='full',\n",
    "             subnetwork_indices=subnetwork_indices)\n",
    "la.fit(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.5475]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(best_model.structure_lin.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   1.,   5.,   9.,   5.,  23.,  27.,  44.,\n",
       "         44.,  64.,  73., 107., 109., 109., 100.,  86.,  71.,  44.,  23.,\n",
       "         27.,  17.,   4.,   2.,   3.,   1.,   0.,   1.]),\n",
       " array([0.33156297, 0.34539825, 0.35923356, 0.37306887, 0.38690415,\n",
       "        0.40073943, 0.41457474, 0.42841005, 0.44224533, 0.45608062,\n",
       "        0.46991593, 0.48375124, 0.49758652, 0.5114218 , 0.52525711,\n",
       "        0.53909242, 0.55292773, 0.56676298, 0.58059829, 0.59443361,\n",
       "        0.60826886, 0.62210417, 0.63593948, 0.64977479, 0.6636101 ,\n",
       "        0.67744535, 0.69128066, 0.70511597, 0.71895123, 0.73278654,\n",
       "        0.74662185]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subnetwork_mask_struct = ModuleNameSubnetMask(best_model, module_names=['structure_lin'])\n",
    "subnetwork_mask_struct.select()\n",
    "subnetwork_mask_struct.indices\n",
    "structure_samples = la.sample(1000)[:, subnetwork_mask_struct.indices]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist(structure_samples.detach().cpu().numpy(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5499], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_samples.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact data_us583dgg>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_samples = la.sample(1000)[:, subnetwork_mask_struct.indices]\n",
    "theta_age = structure_samples[:,0] \n",
    "coords = {'theta_dim_0': [0,],'theta_dim_1':[0,]}\n",
    "dims = {\"theta\":['theta_dim_0', 'theta_dim_1']}\n",
    "data = {'theta':theta_age.detach().cpu().numpy()[None,:,None,None]}\n",
    "post_laplace_theta = az.convert_to_inference_data(data, coords=coords, dims=dims)\n",
    "post_laplace_theta.to_netcdf(\"post_laplace_theta.nc\")\n",
    "\n",
    "post_laplace_all = az.convert_to_inference_data(la.sample(100).detach().cpu().numpy()[None,...])\n",
    "post_laplace_all.to_netcdf(\"post_laplace_all.nc\")\n",
    "\n",
    "art = wandb.Artifact(f\"data_{wandb_logger.experiment.id}\", type=\"xarray\",\n",
    "                        description=\"posterior from laplace model\")\n",
    "art.add_file(\"post_laplace_theta.nc\")\n",
    "art.add_file(\"post_laplace_all.nc\")\n",
    "wandb_logger.experiment.log_artifact(art)\n",
    "# az.convert_to_inference_data(theta_age.detach().cpu().numpy(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "              <div class='xr-header'>\n",
       "                <div class=\"xr-obj-type\">arviz.InferenceData</div>\n",
       "              </div>\n",
       "              <ul class=\"xr-sections group-sections\">\n",
       "              \n",
       "            <li class = \"xr-section-item\">\n",
       "                  <input id=\"idata_posterior5c5e4f73-6558-43d9-adae-f9ad6bf26aa3\" class=\"xr-section-summary-in\" type=\"checkbox\">\n",
       "                  <label for=\"idata_posterior5c5e4f73-6558-43d9-adae-f9ad6bf26aa3\" class = \"xr-section-summary\">posterior</label>\n",
       "                  <div class=\"xr-section-inline-details\"></div>\n",
       "                  <div class=\"xr-section-details\">\n",
       "                      <ul id=\"xr-dataset-coord-list\" class=\"xr-var-list\">\n",
       "                          <div style=\"padding-left:2rem;\"><div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:      (chain: 1, draw: 1000, theta_dim_0: 1, theta_dim_1: 1)\n",
       "Coordinates:\n",
       "  * chain        (chain) int64 0\n",
       "  * draw         (draw) int64 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\n",
       "  * theta_dim_0  (theta_dim_0) int64 0\n",
       "  * theta_dim_1  (theta_dim_1) int64 0\n",
       "Data variables:\n",
       "    theta        (chain, draw, theta_dim_0, theta_dim_1) float32 0.6559 ... 0...\n",
       "Attributes:\n",
       "    created_at:     2023-09-28T12:19:52.085309\n",
       "    arviz_version:  0.16.1</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-2bce517d-15c7-4965-a21d-14ca1dbde6e1' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-2bce517d-15c7-4965-a21d-14ca1dbde6e1' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>chain</span>: 1</li><li><span class='xr-has-index'>draw</span>: 1000</li><li><span class='xr-has-index'>theta_dim_0</span>: 1</li><li><span class='xr-has-index'>theta_dim_1</span>: 1</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-76ef59a5-80b8-404a-9f06-565c6d67b621' class='xr-section-summary-in' type='checkbox'  checked><label for='section-76ef59a5-80b8-404a-9f06-565c6d67b621' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>chain</span></div><div class='xr-var-dims'>(chain)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-007b9c6a-22da-4d93-9733-9b865f93279c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-007b9c6a-22da-4d93-9733-9b865f93279c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bb03afde-92d7-4331-b834-bfe2f46ad745' class='xr-var-data-in' type='checkbox'><label for='data-bb03afde-92d7-4331-b834-bfe2f46ad745' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>draw</span></div><div class='xr-var-dims'>(draw)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 ... 995 996 997 998 999</div><input id='attrs-f1717612-cad2-41e4-8298-010e0dd5c5c5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f1717612-cad2-41e4-8298-010e0dd5c5c5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-23b5d6ec-d9b0-458d-a3b5-b45738622096' class='xr-var-data-in' type='checkbox'><label for='data-23b5d6ec-d9b0-458d-a3b5-b45738622096' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0,   1,   2, ..., 997, 998, 999])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>theta_dim_0</span></div><div class='xr-var-dims'>(theta_dim_0)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-ed10e8bd-c311-4536-8c6e-8583a6a669ab' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ed10e8bd-c311-4536-8c6e-8583a6a669ab' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-061352f6-9995-4779-aee1-37b226a1554a' class='xr-var-data-in' type='checkbox'><label for='data-061352f6-9995-4779-aee1-37b226a1554a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>theta_dim_1</span></div><div class='xr-var-dims'>(theta_dim_1)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-527c2e21-c6d2-474c-984e-867e2152ab99' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-527c2e21-c6d2-474c-984e-867e2152ab99' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-446cc690-eab5-473e-a791-cfa7637847a8' class='xr-var-data-in' type='checkbox'><label for='data-446cc690-eab5-473e-a791-cfa7637847a8' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-019ce221-60cd-4be7-82d3-a282bc58e111' class='xr-section-summary-in' type='checkbox'  checked><label for='section-019ce221-60cd-4be7-82d3-a282bc58e111' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>theta</span></div><div class='xr-var-dims'>(chain, draw, theta_dim_0, theta_dim_1)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.6559 0.6273 ... 0.5723 0.5299</div><input id='attrs-655e8401-9435-40f9-b5c0-16936ccb7804' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-655e8401-9435-40f9-b5c0-16936ccb7804' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d7e9eb7f-a97a-433d-85ba-ba37c1744a4e' class='xr-var-data-in' type='checkbox'><label for='data-d7e9eb7f-a97a-433d-85ba-ba37c1744a4e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[[0.6558524 ]],\n",
       "\n",
       "        [[0.6272531 ]],\n",
       "\n",
       "        [[0.4886943 ]],\n",
       "\n",
       "        [[0.5344822 ]],\n",
       "\n",
       "        [[0.5266729 ]],\n",
       "\n",
       "        [[0.5751865 ]],\n",
       "\n",
       "        [[0.59658617]],\n",
       "\n",
       "        [[0.42814475]],\n",
       "\n",
       "        [[0.54837483]],\n",
       "\n",
       "        [[0.55463415]],\n",
       "\n",
       "...\n",
       "\n",
       "        [[0.57731193]],\n",
       "\n",
       "        [[0.54939353]],\n",
       "\n",
       "        [[0.5722422 ]],\n",
       "\n",
       "        [[0.52186817]],\n",
       "\n",
       "        [[0.55287176]],\n",
       "\n",
       "        [[0.5344859 ]],\n",
       "\n",
       "        [[0.69611824]],\n",
       "\n",
       "        [[0.6248059 ]],\n",
       "\n",
       "        [[0.57227033]],\n",
       "\n",
       "        [[0.52987164]]]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b29d19ee-d9bd-4758-88af-fa11e3d6b0de' class='xr-section-summary-in' type='checkbox'  ><label for='section-b29d19ee-d9bd-4758-88af-fa11e3d6b0de' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>chain</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b9022b57-32c7-4966-b0a1-7c9d97a47bc5' class='xr-index-data-in' type='checkbox'/><label for='index-b9022b57-32c7-4966-b0a1-7c9d97a47bc5' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0], dtype=&#x27;int64&#x27;, name=&#x27;chain&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>draw</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-96f247da-315c-441c-b7b1-ad95ffe8007d' class='xr-index-data-in' type='checkbox'/><label for='index-96f247da-315c-441c-b7b1-ad95ffe8007d' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "       ...\n",
       "       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;draw&#x27;, length=1000))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>theta_dim_0</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-cc506aca-7f0e-429d-a2e6-93d83bf264f6' class='xr-index-data-in' type='checkbox'/><label for='index-cc506aca-7f0e-429d-a2e6-93d83bf264f6' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0], dtype=&#x27;int64&#x27;, name=&#x27;theta_dim_0&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>theta_dim_1</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-59e96d3a-64ec-4d08-b44f-2b173fcedf94' class='xr-index-data-in' type='checkbox'/><label for='index-59e96d3a-64ec-4d08-b44f-2b173fcedf94' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0], dtype=&#x27;int64&#x27;, name=&#x27;theta_dim_1&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d908cc4e-e6c4-447d-9a2b-b36ad1035e15' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d908cc4e-e6c4-447d-9a2b-b36ad1035e15' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>created_at :</span></dt><dd>2023-09-28T12:19:52.085309</dd><dt><span>arviz_version :</span></dt><dd>0.16.1</dd></dl></div></li></ul></div></div><br></div>\n",
       "                      </ul>\n",
       "                  </div>\n",
       "            </li>\n",
       "            \n",
       "              </ul>\n",
       "            </div>\n",
       "            <style> /* CSS stylesheet for displaying InferenceData objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-sections.group-sections {\n",
       "  grid-template-columns: auto;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt, dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       ".xr-wrap{width:700px!important;} </style>"
      ],
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_laplace_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute lppd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-477.9789, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# compute predictive performance\n",
    "preds = []\n",
    "obs = []\n",
    "for data, y_valid in valid_cuda_loader:\n",
    "    pred = la.predictive_samples(data, pred_type='nn', n_samples=100)\n",
    "    preds.append(pred)\n",
    "    obs.append(y_valid)\n",
    "preds = torch.concatenate(preds, dim=1) # shape: (#samples,#data,#params)\n",
    "obs = torch.concatenate(obs, dim=-1)\n",
    "prob = torch.gather(preds, dim=2, index=obs[None,:,None].tile(preds.shape[0], 1,1))\n",
    "log_like = torch.log(prob.squeeze())\n",
    "lppd_valid = (torch.logsumexp(log_like, dim=0) - np.log(preds.shape[0])).sum()\n",
    "wandb_logger.experiment.summary[\"valid_lppd\"] = lppd_valid\n",
    "lppd_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-506.4347, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# compute predictive performance\n",
    "preds = []\n",
    "obs = []\n",
    "for data, y_valid in test_loader:\n",
    "    pred = la.predictive_samples(data, pred_type='nn', n_samples=20)\n",
    "    preds.append(pred)\n",
    "    obs.append(y_valid)\n",
    "preds = torch.concatenate(preds, dim=1) # shape: (#samples,#data,#params)\n",
    "obs = torch.concatenate(obs, dim=-1).to(device=device)\n",
    "prob = torch.gather(preds, dim=2, index=obs[None,:,None].tile(preds.shape[0], 1,1))\n",
    "log_like = torch.log(prob.squeeze())\n",
    "lppd_test = (torch.logsumexp(log_like, dim=0) - np.log(preds.shape[0])).sum()\n",
    "wandb_logger.experiment.summary[\"test_lppd\"] = lppd_test\n",
    "lppd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78053266"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = [AUROC(task=\"multiclass\", num_classes=2)(pred, obs).cpu().numpy() for pred in preds]\n",
    "np.mean(auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0043251133"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test/MulticlassAUROC</td><td></td></tr><tr><td>test/MulticlassAccuracy</td><td></td></tr><tr><td>test/MulticlassAveragePrecision</td><td></td></tr><tr><td>test/MulticlassCalibrationError</td><td></td></tr><tr><td>test/MulticlassF1Score</td><td></td></tr><tr><td>test/loss</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>valid/MulticlassAUROC</td><td></td></tr><tr><td>valid/MulticlassAccuracy</td><td></td></tr><tr><td>valid/MulticlassAveragePrecision</td><td></td></tr><tr><td>valid/MulticlassCalibrationError</td><td></td></tr><tr><td>valid/MulticlassF1Score</td><td></td></tr><tr><td>valid/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>test/MulticlassAUROC</td><td>0.78679</td></tr><tr><td>test/MulticlassAccuracy</td><td>0.98306</td></tr><tr><td>test/MulticlassAveragePrecision</td><td>0.53092</td></tr><tr><td>test/MulticlassCalibrationError</td><td>0.00151</td></tr><tr><td>test/MulticlassF1Score</td><td>0.98306</td></tr><tr><td>test/loss</td><td>0.07676</td></tr><tr><td>test_lppd</td><td>-506.43469</td></tr><tr><td>train/loss_epoch</td><td>0.08154</td></tr><tr><td>train/loss_step</td><td>0.04779</td></tr><tr><td>trainer/global_step</td><td>7800</td></tr><tr><td>valid/MulticlassAUROC</td><td>0.79862</td></tr><tr><td>valid/MulticlassAccuracy</td><td>0.98367</td></tr><tr><td>valid/MulticlassAveragePrecision</td><td>0.53315</td></tr><tr><td>valid/MulticlassCalibrationError</td><td>0.0029</td></tr><tr><td>valid/MulticlassF1Score</td><td>0.98367</td></tr><tr><td>valid_lppd</td><td>-477.97894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laplace</strong> at: <a href='http://141.37.176.203:8080/ddold/laplace_melanoma/runs/us583dgg' target=\"_blank\">http://141.37.176.203:8080/ddold/laplace_melanoma/runs/us583dgg</a><br/> View job at <a href='http://141.37.176.203:8080/ddold/laplace_melanoma/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI2Mjg0/version_details/v10' target=\"_blank\">http://141.37.176.203:8080/ddold/laplace_melanoma/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI2Mjg0/version_details/v10</a><br/>Synced 7 W&B file(s), 0 media file(s), 37 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230928_135009-us583dgg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only some checks\n",
    "compare cross entropy model with Bernoulli likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.base_models import SimpleCnn as SimpleCnnBernoulli, NllLoss\n",
    "from src.semiSub_model import getModel\n",
    "\n",
    "outcome_dist = torch.distributions.Bernoulli  # outcome distributions\n",
    "loss_fn = NllLoss(outcome_dist,\n",
    "                  constrains={'probs': torch.nn.Sigmoid()},\n",
    "                  reduction='mean')\n",
    "\n",
    "bernoulli_model = getModel(SimpleCnnBernoulli, seed=10, weight_decay=1e-4, lr=1e-1, num_structure=1, output_dim=1,\n",
    "                  loss_fn=loss_fn,\n",
    "                  metric_collection=MetricCollection([CalibrationError(task=\"binary\"),\n",
    "                                                     AUROC(task=\"binary\"),\n",
    "                                                     Accuracy(task=\"binary\"),\n",
    "                                                     AveragePrecision(task=\"binary\"),\n",
    "                                                     F1Score(task=\"binary\", threshold=0.1)\n",
    "                                                     ]))\n",
    "print(\"Theta: \", bernoulli_model.structure_lin.weight)\n",
    "print(\"Bias: \", bernoulli_model.dnn[1][-1].bias)\n",
    "\n",
    "wandb_logger = WandbLogger(project='laplace_melanoma', log_model=False, name='BernoulliModel',\n",
    "                            group=\"SimpleCnn\", resume='never')\n",
    "# dm = MelanomDataModuleFromSplit(wandb_logger=wandb_logger,\n",
    "#                                 split=1,\n",
    "#                                 batch_size=256,\n",
    "#                                 reuse_artifact=True,\n",
    "#                                 meta_features=['age_approx'],\n",
    "#                                 transform_test=transform,\n",
    "#                                 transform_train=transform)\n",
    "# dm.prepare_data()\n",
    "# dm.setup()\n",
    "data, y = train_loader.dataset[:]\n",
    "u = data[:,:-1].reshape(-1, 3, 128,128)\n",
    "x = data[:,-1:]\n",
    "ds = torch.utils.data.TensorDataset(u,x,y.to(dtype=torch.float32))\n",
    "b_loader = FastFillTensorDataLoader(ds, batch_size=256, shuffle=True)\n",
    "\n",
    "data, y = valid_cuda_loader.dataset[:]\n",
    "u = data[:,:-1].reshape(-1, 3, 128,128)\n",
    "x = data[:,-1:]\n",
    "ds = torch.utils.data.TensorDataset(u,x,y.to(dtype=torch.float32))\n",
    "b_val_loader = FastFillTensorDataLoader(ds, len(data)//10, shuffle=False)\n",
    "\n",
    "data, y = test_loader.dataset[:]\n",
    "u = data[:,:-1].reshape(-1, 3, 128,128)\n",
    "x = data[:,-1:]\n",
    "ds = torch.utils.data.TensorDataset(u,x,y.to(dtype=torch.float32))\n",
    "b_test_loader = FastFillTensorDataLoader(ds, len(data)//10, shuffle=False)\n",
    "\n",
    "\n",
    "# define a metric we are interested in the best of\n",
    "wandb_logger.experiment.define_metric(\"valid/loss\", summary=\"min\")\n",
    "wandb_logger.experiment.define_metric(\"valid/CalibrationError\", summary=\"min\")\n",
    "wandb_logger.experiment.define_metric(\"valid/AUROC\", summary=\"max\")\n",
    "wandb_logger.experiment.define_metric(\"valid/Accuracy\", summary=\"max\")\n",
    "wandb_logger.experiment.define_metric(\"valid/AveragePrecision\", summary=\"max\")\n",
    "wandb_logger.experiment.define_metric(\"valid/F1Score\", summary=\"max\")\n",
    "ckp_dir = os.path.join(\"wandb_logger.experiment.dir\", \"checkpoints\")\n",
    "callbacks = [ModelCheckpoint(dirpath=ckp_dir, save_top_k=1, monitor=\"valid/loss\")]\n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "                     logger=wandb_logger,\n",
    "                     callbacks=callbacks)\n",
    "trainer.fit(bernoulli_model, train_dataloaders=b_loader, val_dataloaders=b_val_loader)\n",
    "best_bern_model = type(bernoulli_model).load_from_checkpoint(checkpoint_path=callbacks[0].best_model_path)\n",
    "trainer.test(best_bern_model, dataloaders=b_test_loader)\n",
    "\n",
    "wandb_logger.experiment.log_code(\"./\", name=f\"project_code_{wandb_logger.experiment.id}\", exclude_fn=exclude_project_code_dirs) # exclude drbayes, wandb, dnn-mode-connectivity\n",
    "# save model as artifact\n",
    "art = wandb.Artifact(f\"model_state_{wandb_logger.experiment.id}\", type=bernoulli_model.__class__.__name__, description=\"Simple CNN Model\")\n",
    "art.add_dir(ckp_dir)\n",
    "wandb_logger.experiment.log_artifact(art)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  Parameter containing:\n",
      "tensor([[0.5111]], requires_grad=True)\n",
      "Bias:  Parameter containing:\n",
      "tensor([-6.0009], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Theta: \", bernoulli_model.structure_lin.weight)\n",
    "print(\"Bias: \", bernoulli_model.dnn[1][-1].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  Parameter containing:\n",
      "tensor([[0.4771]], requires_grad=True)\n",
      "Bias:  Parameter containing:\n",
      "tensor([-5.2752], requires_grad=True)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Theta: \", best_bern_model.structure_lin.weight)\n",
    "print(\"Bias: \", best_bern_model.dnn[1][-1].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
